# ğŸ­ AI Fitness Tracker - Emotion Detection

## ğŸ“Œ Overview
The **AI Fitness Tracker** is a deep learning-powered system that detects **facial and vocal emotions** in real-time and recommends personalized workouts based on the user's emotional state. It integrates **computer vision, speech processing, and Flask-based web deployment**.

---

## ğŸ“¥ Download Datasets

To train and run the **AI Fitness Tracker**, you need two main datasets:  
one for **voice emotion recognition** and another for **facial emotion detection**.

### ğŸ”Š RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)
The **RAVDESS dataset** contains speech and song recordings with emotional expressions.  
ğŸ“¥ **Download Link**:  
â¡ï¸ [RAVDESS Dataset - Zenodo](https://zenodo.org/record/1188976)  

### ğŸ“¸ Facial Emotion Recognition Dataset (FER 2013)
For facial emotion recognition, we use the **FER 2013** dataset, which contains thousands of labeled facial expressions.  
ğŸ“¥ **Download Links**:  
â¡ï¸ [FER 2013 Dataset - Kaggle](https://www.kaggle.com/datasets/msambare/fer2013)  
â¡ï¸ [FER 2013 Dataset - Papers with Code](https://paperswithcode.com/dataset/fer2013)  

### ğŸ“Œ How to Use These Datasets
1. **Download the datasets** from the links above.  
2. **Extract the files** and place them in the appropriate directories (`datasets/` or any preferred folder).  
3. **Modify the dataset path** in `app2.py` or Jupyter notebooks (`Face_train.ipynb` and `Voice_train.ipynb`) to point to the correct location.  
4. **Train the models** if needed before running the application.  

---

## ğŸš€ Features
âœ… **Facial Emotion Detection** using **MediaPipe** and a pre-trained CNN model.  
âœ… **Voice Emotion Recognition** using **Librosa** and a CNN trained on the **RAVDESS dataset**.  
âœ… **Live Video Streaming** via **Flask** with real-time emotion overlays.  
âœ… **Workout Recommendations** based on detected emotions.  
âœ… **Automatic Logging** of emotions in a CSV file for historical analysis.  
âœ… **Multi-threaded Processing** for efficient face and voice emotion detection.  

---

## ğŸ›  Technologies Used
- **Deep Learning**: TensorFlow, Keras  
- **Computer Vision**: OpenCV, MediaPipe  
- **Speech Processing**: Librosa, PyAudio  
- **Machine Learning**: Scikit-Learn, StandardScaler  
- **Web Framework**: Flask  
- **Data Processing**: NumPy, Pandas, CSV  
- **Threading**: Multi-threaded voice and face processing  

---



## ğŸ“‚ Project Structure
/AI-Fitness-Tracker â”‚â”€â”€ app2.py # Main Flask application for real-time tracking â”‚â”€â”€ emotion_model.h5 # Pre-trained deep learning model for face emotions â”‚â”€â”€ voice_emotion_model.h5 # Pre-trained voice emotion recognition model â”‚â”€â”€ voice_scaler.pkl # StandardScaler for normalizing voice features â”‚â”€â”€ Face_train.ipynb # Jupyter Notebook for face emotion model training â”‚â”€â”€ Voice_train.ipynb # Jupyter Notebook for voice emotion model training â”‚â”€â”€ requirements.txt # Dependencies list for the project â”‚â”€â”€ templates/ â”‚ â””â”€â”€ index.html # Web UI for Flask app (if applicable) â”‚â”€â”€ static/ â”‚ â””â”€â”€ assets/ # CSS, JS, or media files (if applicable)

### 1ï¸âƒ£ Clone the Repository
To get started, clone this repository using the following command:

```bash
git clone https://github.com/your-username/AI-Fitness-Tracker.git
cd AI-Fitness-Tracker
```
### 2ï¸âƒ£ Create a Virtual Environment and Activate It
```bash
# For Linux/Mac
python3 -m venv venv
source venv/bin/activate

# For Windows
python -m venv venv
venv\Scripts\activate
```
### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 4ï¸âƒ£ Run the Flask App
```bash
python app2.py
```
### ğŸ‹ï¸â€â™‚ï¸ How It Works

#### 1ï¸âƒ£ Facial Emotion Detection:
- **Uses a pre-trained CNN model** to analyze real-time facial expressions.
- **MediaPipe processes face landmarks** for better accuracy.

#### 2ï¸âƒ£ Voice Emotion Recognition:
- **Uses Librosa** to extract voice features.
- **CNN model classifies voice into emotional categories.**

#### 3ï¸âƒ£ Workout Recommendation System:
- **Based on detected emotions, the app suggests workouts dynamically.**
- **Example:**
  - If the user feels **stressed**, it may recommend **meditation or yoga**.
  - If the user is **excited**, it may suggest **high-intensity exercises**.

### ğŸ›  Future Enhancements

- ğŸ”¹ **Mobile App Integration** for a seamless experience.
- ğŸ”¹ **More Emotion Categories** for deeper analysis.
- ğŸ”¹ **Support for Wearable Devices** (e.g., Fitbit, Apple Watch).
- ğŸ”¹ **User Authentication** to track progress over time.

